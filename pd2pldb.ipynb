{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pandas 2, Polars, and DuckDB\n",
    "\n",
    "Â© 2023 Matt Harrison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Matt  Harrison @\\_\\_mharrison\\_\\_\n",
    "\n",
    "* Corporate trainer at MetaSnake. Taught Pandas to 1000's of students\n",
    "* Author of Effective Pandas, Machine Learning Pocket Reference, and Illustrated Guide to Python 3.\n",
    "* Advisor at Ponder (creators of Modin, sold to Snowflake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Background\n",
    "\n",
    "* 1999 NLP\n",
    "* 2006 Created Python OLAP Engine\n",
    "* 2009 Heard about Pandas\n",
    "* Used Pandas for failure modeling, analytics, and ml\n",
    "* 2016 Learning the Pandas Library\n",
    "* 2019 Spark\n",
    "* 2020 Pandas Cookbook\n",
    "* 2021 Effective Pandas\n",
    "* 2022 CuDf, Modin, Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 2.0\n",
    "\n",
    "What's new in Pandas 2?\n",
    "\n",
    "Two big things:\n",
    "\n",
    "- Pyarrow types\n",
    "- Copy on write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U polars duckdb jupysql pyarrow pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "billing_data = \\\n",
    "'''cancel_date,period_start,start_date,end_date,rev,sum_payments\n",
    "12/1/2019,1/1/2020,12/15/2019,5/15/2020,999,50\n",
    ",1/1/2020,12/15/2019,5/15/2020,999,50\n",
    ",1/1/2020,12/15/2019,5/15/2020,999,1950\n",
    "1/20/2020,1/1/2020,12/15/2019,5/15/2020,499,0\n",
    ",1/1/2020,12/24/2019,5/24/2020,699,100\n",
    ",1/1/2020,11/29/2019,4/29/2020,799,250\n",
    ",1/1/2020,1/15/2020,4/29/2020,799,250'''\n",
    "\n",
    "bill_df = pd.read_csv(io.StringIO(billing_data),\n",
    "    dtype_backend='pyarrow',                 \n",
    "    parse_dates=['cancel_date', 'period_start', 'start_date',\n",
    "                 'end_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_bill202(df_):\n",
    "    return (df_\n",
    "            .assign(cancel_date=pd.to_datetime(\n",
    "                df_.cancel_date.replace('<NA>', ''), format='%m/%d/%Y')\n",
    "                   )\n",
    "           )\n",
    "\n",
    "tweak_bill202(bill_df).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tweak_bill202(bill_df)\n",
    ".astype({'cancel_date': 'timestamp[ns][pyarrow]',})\n",
    ".astype({col: 'timestamp[ns][pyarrow]' for col in\n",
    "         ['period_start', 'start_date', 'end_date']})\n",
    ".dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_bill203(df_):\n",
    "    return (df_\n",
    "            .assign(cancel_date=pd.to_datetime(\n",
    "                df_.cancel_date.replace('<NA>', ''), format='%m/%d/%Y')\n",
    "                   )\n",
    "            .astype({'cancel_date': 'timestamp[ns][pyarrow]',})\n",
    "            .astype({col: 'timestamp[ns][pyarrow]' for col in\n",
    "                        ['period_start', 'start_date', 'end_date']})\n",
    "              )\n",
    "\n",
    "tweak_bill203(bill_df).dtypes\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply (mis)solution\n",
    "\n",
    "\n",
    "Suppose we are dealing with a company that offers a monthly subscription service. Customers can cancel their subscription at any time, but they are billed at the beginning of each month. In this scenario, we need to calculate the unbilled receivables at the end of each month. Unbilled receivables are the revenues that the company has earned but has not yet billed to the customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_unbilled_rec(vals):\n",
    "    cancel_date, period_start, start_date, end_date, rev, \\\n",
    "         sum_payments = vals\n",
    "    if not pd.isna(cancel_date) and (cancel_date < period_start):\n",
    "        return np.nan\n",
    "    if start_date < period_start and end_date > period_start:\n",
    "        if rev > sum_payments:\n",
    "            return rev - sum_payments\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "(tweak_bill203(bill_df)\n",
    ".assign(unbilled_rec=lambda df_: df_.apply(calc_unbilled_rec, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_unbilled_rec_vectorized(df):\n",
    "    # Conditions\n",
    "    condition_cancel_date = df['cancel_date'].isna() | (df['cancel_date'] >= df['period_start'])\n",
    "    condition_active_subscription = (df['start_date'] < df['period_start']) & (df['end_date'] > df['period_start'])\n",
    "    condition_revenue_greater = df['rev'] > df['sum_payments']\n",
    "\n",
    "    # Apply conditions using pd.DataFrame.where\n",
    "    return ((df['rev'] - df['sum_payments'])\n",
    "            .where(condition_revenue_greater & condition_active_subscription & condition_cancel_date, 0)\n",
    "            .where(condition_active_subscription & condition_cancel_date, np.nan)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "(\n",
    "    tweak_bill203(bill_df)\n",
    "    .assign(unbilled_rec=calc_unbilled_rec_vectorized)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_100k = tweak_bill203(bill_df.sample(100_000, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(bill_100k\n",
    ".assign(unbilled_rec=lambda df_: df_.apply(calc_unbilled_rec, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(bill_100k\n",
    "    .assign(unbilled_rec=calc_unbilled_rec_vectorized)\n",
    "#.assign(unbilled_rec=lambda df_: df_.apply(calc_unbilled_rec, axis=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba Version for Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def calc_unbilled_numba(cancel_date, period_start, start_date, \n",
    "                        end_date, rev, sum_payments):\n",
    "    results = np.full(rev.shape[0], np.nan, dtype=np.float64)\n",
    "    for i in range(rev.shape[0]):\n",
    "        cd = cancel_date[i]\n",
    "        ps = period_start[i]\n",
    "        sd = start_date[i]\n",
    "        ed = end_date[i]\n",
    "        if cd > 0 and cd < ps:\n",
    "            results[i] = np.nan\n",
    "        elif sd < ps < ed:\n",
    "            if rev[i] > sum_payments[i]:\n",
    "                results[i] = rev[i] - sum_payments[i]\n",
    "            else:\n",
    "                results[i] = 0\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(bill_100k\n",
    "    .assign(unbilled_rec=calc_unbilled_numba(*(ser.astype(int).to_numpy() \n",
    "                          for name, ser in bill_100k.items())))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions about Pandas 2?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars\n",
    "\n",
    "* Leverages Arrow (Rust)\n",
    "* Polars is a Rust library with Python bindings\n",
    "* Polars has expressions and contexts\n",
    "  - Contexts - `.select`, `.with_columns`, `.filter`\n",
    "  - Expressions - done w/ `pl.col(\"col_name\")` or `pl.lit(1)`\n",
    "* Lazy evaluation\n",
    "* Query optimization\n",
    "* Multi-threaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import io\n",
    "billing_data = \\\n",
    "'''cancel_date,period_start,start_date,end_date,rev,sum_payments\n",
    "12/1/2019,1/1/2020,12/15/2019,5/15/2020,999,50\n",
    ",1/1/2020,12/15/2019,5/15/2020,999,50\n",
    ",1/1/2020,12/15/2019,5/15/2020,999,1950\n",
    "1/20/2020,1/1/2020,12/15/2019,5/15/2020,499,0\n",
    ",1/1/2020,12/24/2019,5/24/2020,699,100\n",
    ",1/1/2020,11/29/2019,4/29/2020,799,250\n",
    ",1/1/2020,1/15/2020,4/29/2020,799,250'''\n",
    "\n",
    "bill_pl = pl.read_csv(io.StringIO(billing_data))\n",
    "                      \n",
    "bill_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_pl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(bill_pl\n",
    " .with_columns(pl.col(['cancel_date', 'period_start', 'start_date','end_date'])\n",
    "     .str.strptime(pl.Date, '%m/%d/%Y'))\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this to polars expression\n",
    "import numpy as np\n",
    "def calc_unbilled_rec(vals):\n",
    "    cancel_date, period_start, start_date, end_date, rev, \\\n",
    "         sum_payments = vals\n",
    "    if not pd.isna(cancel_date) and (cancel_date < period_start):\n",
    "        return np.nan\n",
    "    if start_date < period_start and end_date > period_start:\n",
    "        if rev > sum_payments:\n",
    "            return rev - sum_payments\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def calc_unbilled_pl():\n",
    "    cancel = pl.col('cancel_date')\n",
    "    period = pl.col('period_start')\n",
    "    start = pl.col('start_date')\n",
    "    end = pl.col('end_date')\n",
    "    rev = pl.col('rev')\n",
    "    sum_payments = pl.col('sum_payments')\n",
    "    res = (pl.when(~cancel.is_null() & (cancel < pl.col('period_start')))\n",
    "              .then(None)\n",
    "             .when((start < period) & (end > period) & (rev > sum_payments))\n",
    "              .then(rev - sum_payments)\n",
    "             .when((start < period) & (end > period))\n",
    "              .then(0)\n",
    "             .otherwise(None)\n",
    "    )\n",
    "    return res\n",
    "\n",
    "(bill_pl\n",
    " .with_columns(pl.col(['cancel_date', 'period_start', 'start_date','end_date'])\n",
    "     .str.strptime(pl.Date, '%m/%d/%Y'))\n",
    "    .with_columns(unbilled_rec=calc_unbilled_pl())\n",
    " )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_100k = pl.from_pandas(bill_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "(pl_100k\n",
    ".with_columns(unbilled_rec=calc_unbilled_pl())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy and Query Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_100k.write_csv('/tmp/bill_100k.csv', datetime_format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_pl_lazy = pl.scan_csv('/tmp/bill_100k.csv')\n",
    "def tweak_pl(df_):\n",
    "    return (df_\n",
    "        .with_columns(pl.col(['cancel_date', 'period_start', 'start_date','end_date'])\n",
    "        .str.strptime(pl.Date, '%m/%d/%Y'))\n",
    "        .with_columns(unbilled_rec=calc_unbilled_pl())\n",
    "    )\n",
    "\n",
    "tweak_pl(bill_pl_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweak_pl(bill_pl_lazy).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB\n",
    "\n",
    "\n",
    "\n",
    "DuckDB is an \"in-process\" SQL OLAP database management system.\n",
    "\n",
    "* No depependencies (written in C++)\n",
    "* No setup. No server (embedded)\n",
    "* Support for complex queries, including window functions, CTEs, and subqueries\n",
    "* Open Source (MIT License)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supporting Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U jupysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.feedback=False\n",
    "%config SqlMagic.displaycon=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql duckdb:///:memory: select 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql duckdb:///:memory: \n",
    "select 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql duckdb:///:memory: \n",
    "df << select 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS bill;\n",
    "CREATE TABLE bill AS FROM read_csv_auto('/tmp/bill_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM bill LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "FROM information_schema.tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "FROM information_schema.columns\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complicated Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    CASE\n",
    "        WHEN (cancel_date IS NULL OR cancel_date >= period_start)\n",
    "            AND start_date < period_start \n",
    "            AND end_date > period_start \n",
    "            AND rev > sum_payments THEN rev - sum_payments\n",
    "        WHEN start_date < period_start AND end_date > period_start AND (cancel_date IS NULL OR cancel_date >= period_start) THEN 0\n",
    "        ELSE NULL\n",
    "    END as unbilled_rec\n",
    "FROM bill;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "bill_pl = pl.read_csv('/tmp/bill_100k.csv')\n",
    "bill_pl = tweak_pl(bill_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DuckDB can read directly from Polars (or Pandas) dataframes\n",
    "duckdb.sql('SELECT * FROM bill_pl LIMIT 5').pl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = duckdb.sql('SELECT * FROM bill_pl LIMIT 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pandas\n",
    "res.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "![Desc.](chart.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "\n",
    "- *Effective Pandas 2* coming out soon\n",
    "- *Effective Polars* in the works \n",
    "\n",
    "Please reach out if your team needs training with Pandas, Polars, or DuckDB.\n",
    "\n",
    "\n",
    "matt@metasnake.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "391a112c5d8063bb1ed75e17f94ea9abfe7bf72365421a70d5e3491b1de003be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
